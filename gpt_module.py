import requests
import re
import time
from requests.exceptions import ChunkedEncodingError, ReadTimeout, HTTPError
import streamlit as st

def call_openrouter(
    prompt: str,
    model: str = "mistralai/mistral-7b-instruct",
    temperature: float = 0.7,
    max_retries: int = 3,
    timeout: float = 60.0
) -> str:
    """
    ç»Ÿä¸€ GPT æ¥å£
    """
    url = "https://openrouter.ai/api/v1/chat/completions"
    key = st.secrets["openrouter_key"]
    headers = {
        "Authorization": f"Bearer {key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature,
    }

    for attempt in range(1, max_retries + 1):
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=timeout)
            resp.raise_for_status()
            return resp.json()["choices"][0]["message"]["content"]
        except (ChunkedEncodingError, ReadTimeout):
            if attempt < max_retries:
                time.sleep(attempt)
                continue
            raise
        except HTTPError:
            raise


def enforce_chinese(text: str) -> str:
    """
    å¦‚æœæ–‡å­—ä¸­ä¸­æ–‡æ¯”ä¾‹å°äº 20%ï¼Œè‡ªåŠ¨è¯·æ±‚ GPT äºŒæ¬¡ç¿»è¯‘æˆä¸­æ–‡
    å¹¶ä¸”ç¦æ­¢è¯æ±‡æ³¨é‡Š
    """
    zh_count = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    total_count = len(text)
    ratio = zh_count / total_count if total_count else 0

    if ratio >= 0.2:
        return text

    # è‡ªåŠ¨äºŒæ¬¡ç¿»è¯‘
    prompt = (
        "è¯·æŠŠä¸‹é¢æ–‡å­—å®Œæ•´ç¿»è¯‘æˆè‡ªç„¶æµç•…çš„ä¸­æ–‡ï¼Œ"
        "ä¸”ä¸è¦åŒ…å«ä»»ä½•å•è¯æ³¨é‡Šã€è¯æ±‡è§£é‡Šï¼Œåªè¦æ­£å¸¸ä¸­æ–‡å¥å­ï¼š\n"
        f"{text}"
    )
    # è¿™é‡Œæ²¿ç”¨ä½ é¡¹ç›®ä¸­çš„ call_openrouter
    from gpt_module import call_openrouter  
    translated = call_openrouter(prompt, temperature=0.3)
    return translated.strip()


def generate_ppt_outline(
    task: str,
    text: str,
    image_paths: list,
    language: str = "zh",
    style: str = "æ­£å¼"
) -> list[dict]:
    """
    ç”Ÿæˆ PPT å¤§çº² + æ­£æ–‡ + å¹»ç¯ç‰‡åŠ¨ç”»æç¤º
    """
    style_zh = {
        "æ­£å¼": "æ­£å¼ç†æ€§",
        "å¹½é»˜": "å¹½é»˜é£è¶£",
        "å„¿ç«¥": "å„¿ç«¥æ˜“æ‡‚",
        "æ–°é—»æ’­éŸ³å‘˜": "æ–°é—»æ’­æŠ¥",
        "å¤é£": "å¤ä»£æ–‡é£",
        "å•†åŠ¡è·¯æ¼”": "å•†åŠ¡è·¯æ¼”",
        "TED": "TEDé£æ ¼",
        "å°çº¢ä¹¦": "å°çº¢ä¹¦å£å»"
    }
    style_en = {
        "formal": "formal academic",
        "humorous": "humorous",
        "child": "child-friendly",
        "news": "news anchor style",
        "classical": "classical style",
        "business": "business pitch",
        "TED": "TED talk style",
        "xiaohongshu": "influencer style"
    }
    style_prompt = style_zh.get(style, "æ­£å¼ç†æ€§") if language == "zh" else style_en.get(style, "formal")

    if language == "zh":
        prompt = (
            f"ä½ æ˜¯ä¸€åä¸“ä¸š PPT è®¾è®¡å¸ˆï¼Œè¯·ç”¨ã€{style_prompt}ã€‘é£æ ¼ï¼Œåªç”¨ä¸­æ–‡è¾“å‡ºã€‚"
            f"è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆ 6~8 é¡µç»“æ„åŒ–å¤§çº²ï¼ˆæ¯é¡µï¼šæ ‡é¢˜ + è¦ç‚¹åˆ—è¡¨ï¼‰ï¼Œ"
            f"ä¸è¦åŒ…å«è¯æ±‡è§£é‡Šæˆ–ç¿»è¯‘ï¼Œ"
            f"å¹¶ä¸”æ¯é¡µæœ€åç»™å‡ºä¸€ä¸ªé€‚åˆçš„ PPT åŠ¨ç”»æ•ˆæœå»ºè®®ï¼ˆä¾‹å¦‚ï¼šæ·¡å…¥ã€æ“¦é™¤ã€é£å…¥ï¼‰ï¼š\n"
            f"ä¸»é¢˜ï¼š{task}\n"
            f"å‚è€ƒæ–‡å­—ï¼ˆå‰1000å­—ï¼‰ï¼š{text[:1000]}"
        )
    else:
        prompt = (
            f"You are a professional PowerPoint designer. Use {style_prompt} style, English only. "
            f"Generate a 6â€“8 slide outline (each slide: Title + bullet points). "
            f"No word-level translations or explanations, "
            f"and recommend one animation for each slide (e.g., fade, fly-in, wipe):\n"
            f"Topic: {task}\n"
            f"Reference text (first 1000 chars): {text[:1000]}"
        )

    raw_outline = call_openrouter(prompt)
    slides = []

    for line in raw_outline.splitlines():
        line = line.strip()
        if not line:
            continue
        m = re.match(r"^(?:Slide\s*\d+[:ï¼š]|å¹»ç¯ç‰‡\s*\d+[:ï¼š]|\d+[\.ã€])\s*(.+)$", line)
        if m:
            slides.append({"title": m.group(1).strip(), "bullets": [], "content": "", "animation": None})
        elif slides and re.match(r"^(?:[-\*â€¢]|\d+[\.ã€])\s+", line):
            point = re.sub(r"^(?:[-\*â€¢]|\d+[\.ã€])\s*", "", line).strip()
            slides[-1]["bullets"].append(point)
        elif ("åŠ¨ç”»" in line or "animation" in line) and slides:
            slides[-1]["animation"] = line.strip()

    # äºŒæ¬¡å±•å¼€
    merged = []
    buf = {"title": "", "content": "", "animation": None}
    char_limit = 300

    for s in slides:
        if not s["bullets"]:
            continue
        pts = "\n".join(s["bullets"])

        exp_prompt = (
            f"è¯·ç”¨ã€{style_prompt}ã€‘é£æ ¼å°†ä»¥ä¸‹è¦ç‚¹å±•å¼€ä¸ºæµç•…è‡ªç„¶çš„å¹»ç¯ç‰‡æ­£æ–‡ï¼Œä¸è¦åŒ…å«è¯æ±‡æ³¨é‡Šæˆ–ç¿»è¯‘ï¼š\n{pts}"
            if language == "zh"
            else f"Please expand the following bullet points into a fluent slide paragraph in {style_prompt} style. "
                 f"No word explanations or translations:\n{pts}"
        )
        paragraph = call_openrouter(exp_prompt, temperature=0.6).strip()

        fact_prompt = (
            f"è¯·åŸºäºè¯¥å¹»ç¯ç‰‡æ­£æ–‡ï¼Œè¡¥å……ä¸€å¥å¯é ç›¸å…³çŸ¥è¯†ï¼ˆæ•°æ®ã€æ¥æºã€äººåï¼‰ï¼Œ100å­—ä»¥å†…ï¼š\n{paragraph}"
            if language == "zh"
            else f"Based on this paragraph, add one related factual knowledge or citation (source, data, person) within 1 sentence:\n{paragraph}"
        )
        fact = call_openrouter(fact_prompt, temperature=0.5).strip()

        enriched = paragraph + ("\n\nğŸ“Œ " + fact if fact else "")

        # åˆå¹¶é€»è¾‘
        if buf["content"] and len(buf["content"]) + len(enriched) < char_limit:
            buf["content"] += "\n" + enriched
        else:
            if buf["content"]:
                merged.append(buf)
            buf = {"title": s["title"], "content": enriched, "animation": s.get("animation")}

    if buf["content"]:
        merged.append(buf)
    return merged